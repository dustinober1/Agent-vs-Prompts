# Chapter 1 — The uncomfortable truth about “better prompts”

## Purpose
Reset expectations and define the book’s core argument.

## Reader takeaway
Prompt tweaks can improve outputs, but they don’t reliably change system behavior; you need structure (tools, state, verification) to scale.

## Key points
- The “prompt improvement curve” and why it flattens
- Why “clever phrasing” feels productive (but often isn’t)
- Prompting as UI text vs prompting as system behavior
- Symptoms of the plateau (regressions, brittle formatting, variance, prompt bloat)
- Reframe: prompts are policies, not solutions

## Case study thread
### Research+Write (Policy change brief)
- Baseline: a single mega prompt asking for a grounded brief “with citations”
- Observe brittleness: inconsistent structure, missing sources, invented rationale
- Identify what the system actually needs: retrieval, citation storage, claim-to-source mapping

### Instructional Design (Annual compliance training)
- Baseline: a single prompt asking for “a compliance course”
- Observe brittleness: objectives and quiz don’t align; content drifts from current policy
- Identify what the system actually needs: policy lookup, alignment checks, approvals

## Artifacts to produce
- A “prompt-only baseline” for each case study (kept intentionally minimal)
- A list of what cannot be solved by prompt text alone

## Chapter exercise
Break the Research+Write and Instructional Design agents into steps, labeling each as “promptable” vs “system-required”.

## Notes / references
- TODO: include 2–3 examples of prompt-only failures (realistic but anonymized)

